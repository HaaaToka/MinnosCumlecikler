{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.3"
    },
    "colab": {
      "name": "quora-question-pairs-data-prep.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OGj2TQRf3FV7",
        "colab_type": "text"
      },
      "source": [
        "# Quora question pairs: data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "NH98uWLO3FWA",
        "colab_type": "text"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWe9pbBo43Ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "9971070a-4277-4ed8-f246-15a092d50e44"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 26 18:41:18 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zOsNgeJT3FWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1405bf35-24a7-44df-f90c-2ab777c1eff5"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import csv, json\n",
        "from zipfile import ZipFile\n",
        "from os.path import expanduser, exists\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "XTNZv2Ot3FWb",
        "colab_type": "text"
      },
      "source": [
        "## Initialize global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eqyC_PfQ3FWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KERAS_DATASETS_DIR = expanduser('/content/')\n",
        "QUESTION_PAIRS_FILE_URL = 'http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv'\n",
        "QUESTION_PAIRS_FILE = 'dev.tsv'\n",
        "GLOVE_ZIP_FILE_URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
        "GLOVE_ZIP_FILE = 'glove.840B.300d.zip'\n",
        "GLOVE_FILE = 'glove.840B.300d.txt'\n",
        "Q1_TRAINING_DATA_FILE = 'q1_dev.npy'\n",
        "Q2_TRAINING_DATA_FILE = 'q2_dev.npy'\n",
        "LABEL_TRAINING_DATA_FILE = 'label_dev.npy'\n",
        "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix_dev.npy'\n",
        "NB_WORDS_DATA_FILE = 'nb_words_dev.json'\n",
        "MAX_NB_WORDS = 200000\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yfltZQNw3FWr",
        "colab_type": "text"
      },
      "source": [
        "## Download and extract questions pairs data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GuHWiOQ93FWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "356262a8-7258-471f-86bc-c2c2c914cd4e"
      },
      "source": [
        "if not exists(KERAS_DATASETS_DIR + QUESTION_PAIRS_FILE):\n",
        "    get_file(QUESTION_PAIRS_FILE, QUESTION_PAIRS_FILE_URL)\n",
        "\n",
        "print(\"Processing\", QUESTION_PAIRS_FILE)\n",
        "\n",
        "question1 = []\n",
        "question2 = []\n",
        "is_duplicate = []\n",
        "with open(KERAS_DATASETS_DIR + QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter='\\t', fieldnames=[\"question1\", \"question2\", \"is_duplicate\"])\n",
        "    for row in reader:\n",
        "        question1.append(row['question1'])\n",
        "        question2.append(row['question2'])\n",
        "        is_duplicate.append(row['is_duplicate'])\n",
        "\n",
        "print('Question pairs: %d' % len(question1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing dev.tsv\n",
            "Question pairs: 40371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7V6yD1WP3FW1",
        "colab_type": "text"
      },
      "source": [
        "## Build tokenized word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "SbG3LAs03FW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc22e267-e2cd-46b4-ec83-bbb2a58acd70"
      },
      "source": [
        "questions = question1 + question2\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(questions)\n",
        "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
        "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(\"Words in index: %d\" % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words in index: 30538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IufNzGpQ3FW8",
        "colab_type": "text"
      },
      "source": [
        "## Download and process GloVe embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "O6-063yJ3FW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b7052874-6b1a-40fa-dba2-4d4f8ff56c2a"
      },
      "source": [
        "# if not exists(KERAS_DATASETS_DIR + GLOVE_ZIP_FILE):\n",
        "#     zipfile = ZipFile(get_file(GLOVE_ZIP_FILE, GLOVE_ZIP_FILE_URL))\n",
        "#     zipfile.extract(GLOVE_FILE, path=KERAS_DATASETS_DIR)\n",
        "    \n",
        "# print(\"Processing\", GLOVE_FILE)\n",
        "\n",
        "# embeddings_index = {}\n",
        "# with open(KERAS_DATASETS_DIR + GLOVE_FILE, encoding='utf-8') as f:\n",
        "#     for line in f:\n",
        "#         values = line.split(' ')\n",
        "#         word = values[0]\n",
        "#         embedding = np.asarray(values[1:], dtype='float32')\n",
        "#         embeddings_index[word] = embedding\n",
        "\n",
        "# print('Word embeddings: %d' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "2176770048/2176768927 [==============================] - 1014s 0us/step\n",
            "Processing glove.840B.300d.txt\n",
            "Word embeddings: 2196016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "m7LKDmah3FXD",
        "colab_type": "text"
      },
      "source": [
        "## Prepare word embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DZ6_EpFK3FXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df03fea2-93ce-4f41-9144-b12ae4fc6e6c"
      },
      "source": [
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NB_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        word_embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 2962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "QW-FmuT13FXK",
        "colab_type": "text"
      },
      "source": [
        "## Prepare training data tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "S25jSvOY3FXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "94ab9731-cf07-4e2e-e65a-c6b950581944"
      },
      "source": [
        "q1_data = pad_sequences(question1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "q2_data = pad_sequences(question2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = np.array(is_duplicate, dtype=int)\n",
        "print('Shape of question1 data tensor:', q1_data.shape)\n",
        "print('Shape of question2 data tensor:', q2_data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of question1 data tensor: (40371, 25)\n",
            "Shape of question2 data tensor: (40371, 25)\n",
            "Shape of label tensor: (40371,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "mvQ8uMRc3FXO",
        "colab_type": "text"
      },
      "source": [
        "## Persist training and configuration data to files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1yk1sZkj3FXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), q1_data)\n",
        "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), q2_data)\n",
        "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
        "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
        "with open(NB_WORDS_DATA_FILE, 'w') as f:\n",
        "    json.dump({'nb_words': nb_words}, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}